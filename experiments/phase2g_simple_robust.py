"""
Phase 2G: ç°¡åŒ–ç©©å¥ç‰ˆ - åˆ†ä½æ•¸å›æ­¸
é‡å° Type 3 éåº¦å¹³æ»‘å•é¡Œçš„æœ€ç°¡å–®è§£æ±ºæ–¹æ¡ˆ

æ ¸å¿ƒæ€æƒ³ï¼š
- Type 3: åªç”¨ Coverageï¼Œç”¨åˆ†ä½æ•¸å›æ­¸ï¼ˆæ›´ç©©å¥ï¼‰
- é æ¸¬ median + ä¸ç¢ºå®šæ€§å€é–“

ä½¿ç”¨æ–¹æ³•:
    python phase2g_simple_robust.py --seed 2024
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import QuantileRegressor
from scipy.interpolate import interp1d
import warnings
import argparse

warnings.filterwarnings('ignore')


def set_seed(seed):
    """è¨­ç½®éš¨æ©Ÿç¨®å­"""
    np.random.seed(seed)
    print(f"âœ“ éš¨æ©Ÿç¨®å­è¨­å®šç‚º: {seed}")


# ==========================================
# Type 3 åˆ†ä½æ•¸å›æ­¸æ¨¡å‹
# ==========================================

class Type3QuantileModel:
    """
    Type 3 å°ˆç”¨ï¼šåˆ†ä½æ•¸å›æ­¸
    
    ç­–ç•¥ï¼š
    1. åªç”¨ Coverageï¼ˆå¿½ç•¥ Thicknessï¼‰
    2. åŒæ™‚é æ¸¬ p10, p50, p90 åˆ†ä½æ•¸
    3. æœ€çµ‚é æ¸¬ç”¨ median (p50)
    """
    
    def __init__(self, X_train, y_train, degree=5):
        """
        Args:
            X_train: [TIM_TYPE, TIM_THICKNESS, TIM_COVERAGE]
            y_train: Theta.JC
            degree: å¤šé …å¼éšæ•¸
        """
        # åªç”¨ Type 3 è³‡æ–™
        type3_mask = X_train[:, 0] == 3
        coverage = X_train[type3_mask, 2].reshape(-1, 1)
        theta = y_train[type3_mask]
        
        self.degree = degree
        
        print(f"\n{'='*60}")
        print(f"è¨“ç·´ Type 3 åˆ†ä½æ•¸å›æ­¸æ¨¡å‹")
        print(f"{'='*60}")
        print(f"è¨“ç·´æ¨£æœ¬æ•¸: {len(coverage)}")
        print(f"Coverage ç¯„åœ: [{coverage.min():.2f}, {coverage.max():.2f}]")
        print(f"Theta.JC ç¯„åœ: [{theta.min():.4f}, {theta.max():.4f}]")
        
        # å¤šé …å¼ç‰¹å¾µ
        self.poly_features = PolynomialFeatures(degree=degree)
        coverage_poly = self.poly_features.fit_transform(coverage)
        
        # è¨“ç·´ 3 å€‹åˆ†ä½æ•¸æ¨¡å‹
        self.quantile_models = {}
        for quantile in [0.1, 0.5, 0.9]:
            model = QuantileRegressor(
                quantile=quantile,
                alpha=0.01,
                solver='highs'
            )
            model.fit(coverage_poly, theta)
            self.quantile_models[quantile] = model
            
            # è¨“ç·´èª¤å·®
            pred = model.predict(coverage_poly)
            mape = np.mean(np.abs((theta - pred) / theta)) * 100
            print(f"  Q{int(quantile*100)} MAPE: {mape:.2f}%")
        
        # ä¿å­˜è¨“ç·´è³‡æ–™çµ±è¨ˆ
        self.train_coverage = coverage.flatten()
        self.train_theta = theta
        
        # æŒ‰ Coverage åˆ†çµ„çµ±è¨ˆ
        self.coverage_stats = {}
        for cov in np.unique(coverage.flatten()):
            mask = coverage.flatten() == cov
            self.coverage_stats[cov] = {
                'mean': np.mean(theta[mask]),
                'median': np.median(theta[mask]),
                'std': np.std(theta[mask]),
                'count': np.sum(mask)
            }
        
        # å»ºç«‹ç°¡å–®çš„æŸ¥è¡¨æ’å€¼ï¼ˆä½œç‚ºå¾Œå‚™ï¼‰
        coverage_unique = sorted(self.coverage_stats.keys())
        medians = [self.coverage_stats[c]['median'] for c in coverage_unique]
        
        self.lookup_interp = interp1d(
            coverage_unique, medians,
            kind='linear', fill_value='extrapolate'
        )
        
        print(f"\nâœ“ æ¨¡å‹è¨“ç·´å®Œæˆ")
        print(f"{'='*60}")
    
    def predict(self, X_test, use_median=True):
        """
        é æ¸¬
        
        Args:
            X_test: [TIM_TYPE, TIM_THICKNESS, TIM_COVERAGE]
            use_median: True=ç”¨ p50, False=ç”¨åŠ æ¬Šçµ„åˆ
        
        Returns:
            predictions, std
        """
        type3_mask = X_test[:, 0] == 3
        n_type3 = np.sum(type3_mask)
        
        if n_type3 == 0:
            return np.zeros(len(X_test)), np.zeros(len(X_test))
        
        coverage = X_test[type3_mask, 2].reshape(-1, 1)
        coverage_poly = self.poly_features.transform(coverage)
        
        predictions = np.zeros(len(X_test))
        stds = np.zeros(len(X_test))
        
        # é æ¸¬ 3 å€‹åˆ†ä½æ•¸
        pred_p10 = self.quantile_models[0.1].predict(coverage_poly)
        pred_p50 = self.quantile_models[0.5].predict(coverage_poly)
        pred_p90 = self.quantile_models[0.9].predict(coverage_poly)
        
        if use_median:
            # ä½¿ç”¨ median
            pred = pred_p50
        else:
            # åŠ æ¬Šçµ„åˆï¼ˆçµ¦æ¥è¿‘è¨“ç·´é›†çš„ coverage æ›´å¤š p50 æ¬Šé‡ï¼‰
            pred = np.zeros(n_type3)
            for i, cov in enumerate(coverage.flatten()):
                if cov in self.coverage_stats:
                    # è¨“ç·´é›†ä¸­è¦‹éï¼Œç›´æ¥ç”¨ median
                    pred[i] = pred_p50[i]
                else:
                    # æœªè¦‹éï¼Œç”¨åˆ†ä½æ•¸åŠ æ¬Š
                    pred[i] = 0.2 * pred_p10[i] + 0.6 * pred_p50[i] + 0.2 * pred_p90[i]
        
        predictions[type3_mask] = pred
        
        # ä¸ç¢ºå®šæ€§ä¼°è¨ˆ (IQR / 1.35)
        iqr = pred_p90 - pred_p10
        stds[type3_mask] = iqr / 1.35
        
        return predictions, stds


# ==========================================
# Type 1, 2 ç°¡å–®æ¨¡å‹
# ==========================================

class SimplePolyModel:
    """Type 1, 2 ç”¨å¤šé …å¼å›æ­¸"""
    
    def __init__(self, X_train, y_train):
        """
        Args:
            X_train: [TIM_TYPE, TIM_THICKNESS, TIM_COVERAGE]
            y_train: Theta.JC
        """
        # åªç”¨ Type 1, 2 è³‡æ–™
        others_mask = X_train[:, 0] != 3
        X_others = X_train[others_mask]
        y_others = y_train[others_mask]
        
        print(f"\nè¨“ç·´ Type 1, 2 æ¨¡å‹ ({len(X_others)} ç­†)...")
        
        # å¤šé …å¼ç‰¹å¾µ
        self.poly_features = PolynomialFeatures(degree=2, interaction_only=False)
        X_poly = self.poly_features.fit_transform(X_others)
        
        # Quantile å›æ­¸ (median)
        self.model = QuantileRegressor(quantile=0.5, alpha=0.01, solver='highs')
        self.model.fit(X_poly, y_others)
        
        # è¨“ç·´èª¤å·®
        pred = self.model.predict(X_poly)
        mape = np.mean(np.abs((y_others - pred) / y_others)) * 100
        print(f"  è¨“ç·´ MAPE: {mape:.2f}%")
    
    def predict(self, X_test):
        """é æ¸¬"""
        others_mask = X_test[:, 0] != 3
        
        predictions = np.zeros(len(X_test))
        stds = np.zeros(len(X_test))
        
        if np.sum(others_mask) > 0:
            X_others = X_test[others_mask]
            X_poly = self.poly_features.transform(X_others)
            predictions[others_mask] = self.model.predict(X_poly)
            stds[others_mask] = 0.01  # é è¨­å€¼
        
        return predictions, stds


# ==========================================
# æ··åˆæ¨¡å‹
# ==========================================

class HybridQuantileModel:
    """æ··åˆæ¨¡å‹ï¼šType 3 ç”¨åˆ†ä½æ•¸å›æ­¸ï¼ŒType 1/2 ç”¨æ¨™æº–æ¨¡å‹"""
    
    def __init__(self, X_train, y_train, config):
        """åˆå§‹åŒ–"""
        # Type 3 åˆ†ä½æ•¸æ¨¡å‹
        self.type3_model = Type3QuantileModel(X_train, y_train, degree=config['degree'])
        
        # Type 1, 2 æ¨¡å‹
        self.standard_model = SimplePolyModel(X_train, y_train)
    
    def predict(self, X_test):
        """é æ¸¬"""
        # Type 3 é æ¸¬
        pred_type3, std_type3 = self.type3_model.predict(X_test, use_median=True)
        
        # Type 1, 2 é æ¸¬
        pred_others, std_others = self.standard_model.predict(X_test)
        
        # çµ„åˆ
        predictions = pred_type3 + pred_others
        stds = std_type3 + std_others
        
        return predictions, stds


# ==========================================
# è©•ä¼°å‡½æ•¸
# ==========================================

def evaluate_model(model, X_test, y_test, verbose=True):
    """è©•ä¼°æ¨¡å‹"""
    y_pred, y_std = model.predict(X_test)
    
    # è¨ˆç®—æŒ‡æ¨™
    relative_errors = np.abs((y_test - y_pred) / y_test) * 100
    
    mape = np.mean(relative_errors)
    mae = np.mean(np.abs(y_test - y_pred))
    max_error = np.max(relative_errors)
    
    outliers_20 = np.sum(relative_errors > 20)
    outliers_15 = np.sum(relative_errors > 15)
    outliers_10 = np.sum(relative_errors > 10)
    
    # Type 3 åˆ†æ
    type3_mask = X_test[:, 0] == 3
    if np.sum(type3_mask) > 0:
        type3_errors = relative_errors[type3_mask]
        type3_mape = np.mean(type3_errors)
        type3_outliers = np.sum(type3_errors > 20)
        
        # Coverage 0.8 åˆ†æ
        cov08_mask = type3_mask & (X_test[:, 2] == 0.8)
        if np.sum(cov08_mask) > 0:
            cov08_errors = relative_errors[cov08_mask]
            cov08_mape = np.mean(cov08_errors)
            cov08_outliers = np.sum(cov08_errors > 20)
            
            # è©³ç´°é¡¯ç¤º Coverage 0.8 é æ¸¬
            if verbose:
                print(f"\n{'='*60}")
                print("Coverage 0.8 è©³ç´°é æ¸¬")
                print(f"{'='*60}")
                cov08_data = X_test[cov08_mask]
                cov08_true = y_test[cov08_mask]
                cov08_pred = y_pred[cov08_mask]
                cov08_err = relative_errors[cov08_mask]
                
                for i in range(len(cov08_true)):
                    marker = "âŒ" if cov08_err[i] > 20 else "âœ“"
                    print(f"{marker} Thick={cov08_data[i, 1]:.0f}, "
                          f"True={cov08_true[i]:.3f}, Pred={cov08_pred[i]:.3f}, "
                          f"Error={cov08_err[i]:.1f}%")
        else:
            cov08_mape = 0
            cov08_outliers = 0
    else:
        type3_mape = 0
        type3_outliers = 0
        cov08_mape = 0
        cov08_outliers = 0
    
    if verbose:
        print(f"\n{'='*60}")
        print(f"è©•ä¼°çµæœ (åˆ†ä½æ•¸å›æ­¸)")
        print(f"{'='*60}")
        print(f"æ¨£æœ¬æ•¸: {len(y_test)}")
        print(f"\næº–ç¢ºåº¦:")
        print(f"  MAPE:      {mape:.2f}%")
        print(f"  MAE:       {mae:.4f}")
        print(f"  Max Error: {max_error:.2f}%")
        print(f"\nç•°å¸¸é»:")
        print(f"  >20%: {outliers_20}/{len(y_test)} ({outliers_20/len(y_test)*100:.2f}%)")
        print(f"  >15%: {outliers_15}/{len(y_test)} ({outliers_15/len(y_test)*100:.2f}%)")
        print(f"  >10%: {outliers_10}/{len(y_test)} ({outliers_10/len(y_test)*100:.2f}%)")
        
        if np.sum(type3_mask) > 0:
            print(f"\nType 3 è©³ç´°:")
            print(f"  æ¨£æœ¬æ•¸: {np.sum(type3_mask)}")
            print(f"  MAPE: {type3_mape:.2f}%")
            print(f"  ç•°å¸¸é»: {type3_outliers}/{np.sum(type3_mask)}")
            if np.sum(cov08_mask) > 0:
                print(f"\n  Coverage 0.8 å­é›†:")
                print(f"    MAPE: {cov08_mape:.2f}%")
                print(f"    ç•°å¸¸é»: {cov08_outliers}/{np.sum(cov08_mask)}")
        print(f"{'='*60}\n")
    
    results = {
        'mape': mape,
        'mae': mae,
        'max_error': max_error,
        'outliers_20': outliers_20,
        'type3_mape': type3_mape,
        'type3_outliers': type3_outliers,
        'cov08_mape': cov08_mape,
        'cov08_outliers': cov08_outliers,
        'predictions': y_pred,
        'std': y_std,
        'errors': relative_errors
    }
    
    return results


def save_predictions(X_test, y_test, results, filename):
    """ä¿å­˜é æ¸¬çµæœ"""
    df = pd.DataFrame({
        'TIM_TYPE': X_test[:, 0],
        'TIM_THICKNESS': X_test[:, 1],
        'TIM_COVERAGE': X_test[:, 2],
        'True': y_test,
        'Predicted': results['predictions'],
        'Error%': results['errors'],
        'Std': results['std']
    })
    
    df.to_csv(filename, index=False)
    print(f"âœ“ é æ¸¬çµæœå·²ä¿å­˜åˆ°: {filename}")


# ==========================================
# ä¸»å‡½æ•¸
# ==========================================

def main(seed=2024, verbose=True):
    """ä¸»è¨“ç·´æµç¨‹"""
    set_seed(seed)
    
    print("\n" + "="*60)
    print("Phase 2G: ç°¡åŒ–ç©©å¥ç‰ˆ - åˆ†ä½æ•¸å›æ­¸")
    print("="*60)
    
    # ç‰¹å¾µå’Œç›®æ¨™
    feature_cols = ['TIM_TYPE', 'TIM_THICKNESS', 'TIM_COVERAGE']
    target_col = 'Theta.JC'
    
    # é…ç½®
    config = {
        'degree': 5,  # å¤šé …å¼éšæ•¸
        'seed': seed,
    }
    
    print(f"\né…ç½®: å¤šé …å¼éšæ•¸ = {config['degree']}")
    
    # è¼‰å…¥è³‡æ–™
    train_above = pd.read_excel('data/train/Above.xlsx')
    test_above = pd.read_excel('data/test/Above.xlsx')
    
    # è¨“ç·´é›†æ¸…ç†
    train_above_clean = train_above.groupby(feature_cols, as_index=False).agg({
        target_col: 'mean'
    })
    
    print(f"\nè¨“ç·´é›†: {len(train_above_clean)} ç­†")
    print(f"æ¸¬è©¦é›†: {len(test_above)} ç­†")
    
    X_train = train_above_clean[feature_cols].values
    y_train = train_above_clean[target_col].values
    
    X_test = test_above[feature_cols].values
    y_test = test_above[target_col].values
    
    # è¨“ç·´æ··åˆæ¨¡å‹
    model = HybridQuantileModel(X_train, y_train, config)
    
    # è©•ä¼°
    results = evaluate_model(model, X_test, y_test, verbose=verbose)
    
    # ä¿å­˜é æ¸¬çµæœ
    save_predictions(X_test, y_test, results,
                     f'phase2g_quantile_seed{seed}_predictions.csv')
    
    # ç¸½çµ
    print("\n" + "="*60)
    print("æœ€çµ‚çµæœç¸½çµ (Phase 2G)")
    print("="*60)
    print(f"ç­–ç•¥:")
    print(f"  âœ“ Type 3: å®Œå…¨å¿½ç•¥ Thickness")
    print(f"  âœ“ Type 3: åˆ†ä½æ•¸å›æ­¸ (p10, p50, p90)")
    print(f"  âœ“ Type 1, 2: Median å›æ­¸")
    print(f"\nçµæœ:")
    print(f"  ç¸½é«” MAPE: {results['mape']:.2f}%")
    print(f"  Type 3 MAPE: {results['type3_mape']:.2f}%")
    print(f"  Coverage 0.8 MAPE: {results['cov08_mape']:.2f}%")
    print(f"  ç•°å¸¸é»: {results['outliers_20']}/{len(y_test)}")
    print("="*60 + "\n")
    
    return results


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Phase 2G åˆ†ä½æ•¸å›æ­¸')
    parser.add_argument('--seed', type=int, default=2024, help='éš¨æ©Ÿç¨®å­')
    parser.add_argument('-v', '--verbose', action='store_true', help='è©³ç´°æ¨¡å¼')
    
    args = parser.parse_args()
    
    results = main(seed=args.seed, verbose=args.verbose)
    
    print("\nğŸ’¡ èªªæ˜:")
    print("  æ­¤ç‰ˆæœ¬ä½¿ç”¨åˆ†ä½æ•¸å›æ­¸ï¼ˆæœ€ç°¡å–®ç©©å¥ï¼‰")
    print("  é æ¸¬ median è€Œé meanï¼ˆå°ç•°å¸¸å€¼æ›´ç©©å¥ï¼‰\n")
