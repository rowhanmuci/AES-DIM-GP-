"""
ç•°å¸¸é»æ·±åº¦åˆ†æ - é‡å°TIM_TYPE=3
ç™¼ç¾: 10å€‹ç•°å¸¸é»ä¸­7å€‹éƒ½æ˜¯TIM_TYPE=3ï¼Œä¸”THICKNESSéƒ½å¾ˆå¤§
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_tim_type3_outliers():
    """åˆ†æTIM_TYPE=3ç‚ºä½•ç•°å¸¸"""
    
    print("="*60)
    print("TIM_TYPE=3 ç•°å¸¸é»æ·±åº¦åˆ†æ")
    print("="*60 + "\n")
    
    # è¼‰å…¥è³‡æ–™
    train_df = pd.read_excel('data/train/Above.xlsx')
    test_df = pd.read_csv('phase1_above_predictions.csv')
    
    # åˆ†é›¢ç•°å¸¸é»
    outliers = test_df[test_df['Error%'] > 20]
    normals = test_df[test_df['Error%'] <= 20]
    
    print(f"ç•°å¸¸é»ç¸½æ•¸: {len(outliers)}")
    print(f"TIM_TYPE=3çš„ç•°å¸¸é»: {len(outliers[outliers['TIM_TYPE'] == 3])}\n")
    
    # åˆ†æ1: TIM_TYPE=3åœ¨è¨“ç·´é›†ä¸­çš„åˆ†å¸ƒ
    print("="*60)
    print("è¨“ç·´é›†ä¸­TIM_TYPEåˆ†å¸ƒ")
    print("="*60 + "\n")
    
    type_counts_train = train_df['TIM_TYPE'].value_counts().sort_index()
    print("è¨“ç·´é›†:")
    for tim_type, count in type_counts_train.items():
        pct = count / len(train_df) * 100
        print(f"  Type {tim_type}: {count} ç­† ({pct:.2f}%)")
    
    print("\næ¸¬è©¦é›†:")
    type_counts_test = test_df['TIM_TYPE'].value_counts().sort_index()
    for tim_type, count in type_counts_test.items():
        pct = count / len(test_df) * 100
        print(f"  Type {tim_type}: {count} ç­† ({pct:.2f}%)")
    
    # åˆ†æ2: TIM_TYPE=3çš„THICKNESSåˆ†å¸ƒ
    print("\n" + "="*60)
    print("TIM_TYPE=3çš„THICKNESSåˆ†æ")
    print("="*60 + "\n")
    
    train_type3 = train_df[train_df['TIM_TYPE'] == 3]
    test_type3 = test_df[test_df['TIM_TYPE'] == 3]
    outlier_type3 = outliers[outliers['TIM_TYPE'] == 3]
    
    print("THICKNESSçµ±è¨ˆ:")
    print(f"\nè¨“ç·´é›† (Type 3):")
    print(f"  ç¯„åœ: [{train_type3['TIM_THICKNESS'].min():.1f}, {train_type3['TIM_THICKNESS'].max():.1f}]")
    print(f"  å¹³å‡: {train_type3['TIM_THICKNESS'].mean():.1f}")
    print(f"  ä¸­ä½æ•¸: {train_type3['TIM_THICKNESS'].median():.1f}")
    
    print(f"\næ¸¬è©¦é›† (Type 3):")
    print(f"  ç¯„åœ: [{test_type3['TIM_THICKNESS'].min():.1f}, {test_type3['TIM_THICKNESS'].max():.1f}]")
    print(f"  å¹³å‡: {test_type3['TIM_THICKNESS'].mean():.1f}")
    
    print(f"\nç•°å¸¸é» (Type 3):")
    print(f"  ç¯„åœ: [{outlier_type3['TIM_THICKNESS'].min():.1f}, {outlier_type3['TIM_THICKNESS'].max():.1f}]")
    print(f"  å¹³å‡: {outlier_type3['TIM_THICKNESS'].mean():.1f}")
    
    # æª¢æŸ¥å¤–æ¨
    train_max_thick = train_type3['TIM_THICKNESS'].max()
    outlier_thick = outlier_type3['TIM_THICKNESS'].values
    
    print(f"\nâš ï¸  å¤–æ¨å•é¡Œ:")
    out_of_range = outlier_thick[outlier_thick > train_max_thick]
    if len(out_of_range) > 0:
        print(f"  {len(out_of_range)} å€‹ç•°å¸¸é»çš„THICKNESSè¶…å‡ºè¨“ç·´ç¯„åœ")
        print(f"  è¨“ç·´æœ€å¤§å€¼: {train_max_thick:.1f}")
        print(f"  ç•°å¸¸é»è¶…å‡ºå€¼: {out_of_range}")
    else:
        print(f"  æ‰€æœ‰ç•°å¸¸é»éƒ½åœ¨è¨“ç·´ç¯„åœå…§")
    
    # åˆ†æ3: ä¸åŒCOVERAGEçš„è¡¨ç¾
    print("\n" + "="*60)
    print("TIM_TYPE=3çš„COVERAGEåˆ†æ")
    print("="*60 + "\n")
    
    for coverage in sorted(outlier_type3['TIM_COVERAGE'].unique()):
        subset = outlier_type3[outlier_type3['TIM_COVERAGE'] == coverage]
        print(f"COVERAGE={coverage}:")
        print(f"  ç•°å¸¸é»æ•¸: {len(subset)}")
        print(f"  å¹³å‡èª¤å·®: {subset['Error%'].mean():.2f}%")
        print(f"  THICKNESSç¯„åœ: [{subset['TIM_THICKNESS'].min():.1f}, {subset['TIM_THICKNESS'].max():.1f}]")
        print()
    
    # åˆ†æ4: è¨“ç·´é›†ä¸­Type3çš„Theta.JCåˆ†å¸ƒ
    print("="*60)
    print("Theta.JCåˆ†å¸ƒæ¯”è¼ƒ")
    print("="*60 + "\n")
    
    print(f"è¨“ç·´é›† (Type 3):")
    print(f"  ç¯„åœ: [{train_type3['Theta.JC'].min():.4f}, {train_type3['Theta.JC'].max():.4f}]")
    print(f"  å¹³å‡: {train_type3['Theta.JC'].mean():.4f}")
    
    print(f"\nç•°å¸¸é» (Type 3):")
    print(f"  çœŸå¯¦å€¼ç¯„åœ: [{outlier_type3['Theta.JC'].min():.4f}, {outlier_type3['Theta.JC'].max():.4f}]")
    print(f"  é æ¸¬å€¼ç¯„åœ: [{outlier_type3['Prediction'].min():.4f}, {outlier_type3['Prediction'].max():.4f}]")
    
    # è¦–è¦ºåŒ–
    create_type3_visualization(train_df, test_df, outliers)
    
    # æ”¹é€²å»ºè­°
    print("\n" + "="*60)
    print("ğŸ’¡ æ”¹é€²å»ºè­°")
    print("="*60 + "\n")
    
    suggestions = [
        "1. TIM_TYPE=3çš„æ¨£æœ¬å¯èƒ½éœ€è¦ç‰¹æ®Šè™•ç†",
        "2. å¤§THICKNESSå€¼çš„å¤–æ¨å•é¡Œ â†’ è€ƒæ…®å¢åŠ å¤§THICKNESSçš„è¨“ç·´æ¨£æœ¬",
        "3. TIM_TYPEå¯èƒ½éœ€è¦æ›´å¥½çš„ç‰¹å¾µè¡¨ç¤º (Entity Embedding)",
        "4. è€ƒæ…®å°TIM_TYPE=3ä½¿ç”¨ä¸åŒçš„æ¨¡å‹æˆ–åƒæ•¸",
        "5. å°å¤§THICKNESSå€åŸŸä½¿ç”¨æ¨£æœ¬åŠ æ¬Šè¨“ç·´",
    ]
    
    for s in suggestions:
        print(f"  {s}")
    
    print("\n" + "="*60 + "\n")


def create_type3_visualization(train_df, test_df, outliers):
    """å‰µå»ºTIM_TYPE=3çš„è¦–è¦ºåŒ–"""
    
    print("ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('TIM_TYPE=3 ç•°å¸¸é»åˆ†æ', fontsize=16, fontweight='bold')
    
    # 1. THICKNESSåˆ†å¸ƒå°æ¯”
    ax1 = axes[0, 0]
    
    train_type3 = train_df[train_df['TIM_TYPE'] == 3]
    test_type3 = test_df[test_df['TIM_TYPE'] == 3]
    outlier_type3 = outliers[outliers['TIM_TYPE'] == 3]
    normal_type3 = test_type3[test_type3['Error%'] <= 20]
    
    ax1.hist(train_type3['TIM_THICKNESS'], bins=20, alpha=0.5, label='Training', color='blue')
    ax1.hist(normal_type3['TIM_THICKNESS'], bins=20, alpha=0.5, label='Test (Normal)', color='green')
    ax1.hist(outlier_type3['TIM_THICKNESS'], bins=10, alpha=0.7, label='Test (Outliers)', color='red')
    
    ax1.set_xlabel('TIM_THICKNESS')
    ax1.set_ylabel('Count')
    ax1.set_title('TIM_TYPE=3: THICKNESSåˆ†å¸ƒ')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. Theta.JC vs THICKNESS (Type 3 only)
    ax2 = axes[0, 1]
    
    ax2.scatter(train_type3['TIM_THICKNESS'], train_type3['Theta.JC'], 
               alpha=0.3, s=20, label='Training', color='blue')
    ax2.scatter(normal_type3['TIM_THICKNESS'], normal_type3['Theta.JC'], 
               alpha=0.7, s=50, label='Test (Normal)', color='green')
    ax2.scatter(outlier_type3['TIM_THICKNESS'], outlier_type3['Theta.JC'], 
               alpha=0.9, s=100, marker='X', label='Test (Outliers)', color='red')
    
    ax2.set_xlabel('TIM_THICKNESS')
    ax2.set_ylabel('Theta.JC')
    ax2.set_title('TIM_TYPE=3: Theta.JC vs THICKNESS')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. èª¤å·® vs THICKNESS
    ax3 = axes[1, 0]
    
    ax3.scatter(test_type3['TIM_THICKNESS'], test_type3['Error%'], 
               c=test_type3['Error%'], cmap='RdYlGn_r', s=100, alpha=0.7)
    ax3.axhline(y=20, color='red', linestyle='--', linewidth=2, label='Threshold (20%)')
    
    ax3.set_xlabel('TIM_THICKNESS')
    ax3.set_ylabel('Relative Error (%)')
    ax3.set_title('TIM_TYPE=3: èª¤å·® vs THICKNESS')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. ä¸åŒCOVERAGEçš„èª¤å·®åˆ†å¸ƒ
    ax4 = axes[1, 1]
    
    coverage_values = sorted(test_type3['TIM_COVERAGE'].unique())
    errors_by_coverage = [test_type3[test_type3['TIM_COVERAGE'] == c]['Error%'].values 
                         for c in coverage_values]
    
    bp = ax4.boxplot(errors_by_coverage, labels=[f'{c}' for c in coverage_values])
    ax4.axhline(y=20, color='red', linestyle='--', linewidth=2, label='Threshold')
    
    ax4.set_xlabel('TIM_COVERAGE')
    ax4.set_ylabel('Relative Error (%)')
    ax4.set_title('TIM_TYPE=3: ä¸åŒCOVERAGEçš„èª¤å·®åˆ†å¸ƒ')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('tim_type3_analysis.png', dpi=300, bbox_inches='tight')
    print("âœ“ è¦–è¦ºåŒ–å·²ä¿å­˜: tim_type3_analysis.png\n")
    plt.close()


if __name__ == "__main__":
    analyze_tim_type3_outliers()
